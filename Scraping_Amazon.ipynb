{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "%autosave 120\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 'IMDB' df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_imdb = pickle.load(open(\"final_imdb.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'Amazon Files' function: Using AmazonID, scrape Amazon pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page = 1\n",
    "num = 1\n",
    "\n",
    "for amzid in final_imdb['amazonid']:\n",
    "    t0 = time.time()\n",
    "    response_delay = time.time() - t0\n",
    "    time.sleep(10*response_delay)  # wait 10x longer than it took them to respond\n",
    "    \n",
    "    website = 'https://www.amazon.com/exec/obidos/ASIN/%s/internetmoviedat/'\n",
    "    url = website % amzid\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36'}\n",
    "    soup =BeautifulSoup(requests.get(url, headers = header).text, \"lxml\")\n",
    " \n",
    "    pretty_amazon = str(soup.prettify)\n",
    "    pickle.dump(pretty_amazon, open(\"amazon_%s.p\" % num, \"wb\"))\n",
    "    \n",
    "    print('Scraped page %d out of 606' % page)\n",
    "    page += 1\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find & remove 'Robot Check' files from 'Amazon' files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amazon_frame = pd.DataFrame()\n",
    "amazon_frame['amazonid'] = final_imdb['amazonid']\n",
    "amazon_frame['film'] = final_imdb['title']\n",
    "amazon_frame['file_index'] = final_imdb.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def page_header(a, b):\n",
    "    df = pd.DataFrame()\n",
    "    header = []\n",
    "    amazonid = []\n",
    "    \n",
    "    for number in range(a, b):\n",
    "        soup = BeautifulSoup(pickle.load(open(\"amazon_%d.p\" %number, \"rb\")), \"lxml\")        \n",
    "\n",
    "        item1 = str(soup.find_all('title')[0].text)\n",
    "        header.append(item1)    \n",
    "\n",
    "    df['header'] = header\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon_headers = page_header(1,607)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon_frame['header'] = amazon_headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 'Amazon' function: From Amazon files, get Amazon ID, Stars, Reviews, Ranks, Language, Publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def amazon_page(number):\n",
    "\n",
    "    file_df = pd.DataFrame()\n",
    "\n",
    "    amazonid = []\n",
    "    title_author = []\n",
    "    stars = []\n",
    "    reviews = []\n",
    "    bs_rank = []\n",
    "    language = []\n",
    "    publisher = []\n",
    "\n",
    "    soup = BeautifulSoup(pickle.load(open(\"amazon_%d.p\" % number, \"rb\")), \"lxml\")\n",
    "    \n",
    "    try:\n",
    "        item1 = str(soup.find_all('title')[0].text).rpartition(\n",
    "            ':')[0].rpartition(':')[0].rpartition(':')[0]\n",
    "        title_author.append(item1)\n",
    "    except: \n",
    "        title_author.append(np.nan)\n",
    "        #Turns out the location of the title & author in the header is inconsistent.\n",
    "    \n",
    "    try:\n",
    "        item2 = soup.find_all('span', {'class': 'reviewCountTextLinkedHistogram'})[0].get('title')\n",
    "        stars.append(item2)\n",
    "    except:\n",
    "        stars.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        item3 = soup.find_all('span', {'id': 'acrCustomerReviewText'})[0].text\n",
    "        reviews.append(item3)\n",
    "    except:\n",
    "        reviews.append(np.nan)\n",
    "\n",
    "    try:     \n",
    "        item4 = soup.findAll(attrs={\"id\" : \"amsDetailRightPBookTall\"})[0].get('data-detailpageasin')\n",
    "        amazonid.append(item4)\n",
    "    except:\n",
    "        amazonid.append(np.nan)\n",
    "    \n",
    "    try: \n",
    "        item5 = soup.find_all('li', {'id': 'SalesRank'})[0].find('span').text\n",
    "        bs_rank.append(item5)    \n",
    "    except:\n",
    "        bs_rank.append(np.nan)\n",
    "\n",
    "    try: \n",
    "        for child in soup.find_all('td', {'class' : 'bucket'})[0].find_all('li'):\n",
    "            if \"Language\" in str(child.text):\n",
    "                language.append(str(child.text))\n",
    "    except:\n",
    "        language.append(np.nan) \n",
    "\n",
    "    try: \n",
    "        for child in soup.find_all('td', {'class' : 'bucket'})[0].find_all('li'):\n",
    "            if \"Publisher\" in str(child.text):\n",
    "                publisher.append(str(child.text))\n",
    "    except:\n",
    "        publisher.append(np.nan) \n",
    "        \n",
    "    del soup\n",
    "\n",
    "    file_df['amazonid'] = amazonid\n",
    "    file_df['title_author'] = title_author\n",
    "    file_df['stars'] = stars\n",
    "    file_df['reviews'] = reviews\n",
    "    file_df['bs_rank'] = bs_rank\n",
    "    file_df['language'] = language\n",
    "    file_df['publisher'] = publisher\n",
    "    \n",
    "    \n",
    "    return file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page = 1\n",
    "for number in range (1, 531):\n",
    "    df = amazon_page(int(number))\n",
    "    header_list.append(df)\n",
    "    print('Scraping file %d out of 530' % page)\n",
    "    page +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_amazon = pd.concat(amazon_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_amazon = final_amazon.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Amazon' function: From Amazon files, rescrape header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rescrape header without any rpartition.\n",
    "def amazon_header(number):\n",
    "\n",
    "    file_df = pd.DataFrame()\n",
    "\n",
    "    amazonid = []\n",
    "    header = []\n",
    "\n",
    "    soup = BeautifulSoup(pickle.load(open(\"amazon_%d.p\" % number, \"rb\")), \"lxml\")\n",
    "    \n",
    "    try:\n",
    "        item1 = str(soup.find_all('title')[0].text)\n",
    "        header.append(item1)\n",
    "    except: \n",
    "        title_author.append(np.nan)\n",
    "    \n",
    "    try:     \n",
    "        item4 = soup.findAll(attrs={\"id\" : \"amsDetailRightPBookTall\"})[0].get('data-detailpageasin')\n",
    "        amazonid.append(item4)\n",
    "    except:\n",
    "        amazonid.append(np.nan)\n",
    "    \n",
    "    del soup\n",
    "\n",
    "    file_df['amazonid'] = amazonid\n",
    "    file_df['header'] = header\n",
    "    \n",
    "    \n",
    "    return file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page = 1\n",
    "for number in range (1, 531):\n",
    "    df = amazon_header(int(number))\n",
    "    header_list.append(df)\n",
    "    print('Scraping file %d out of 530' % page)\n",
    "    page +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_header = pd.concat(header_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_header = final_header.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(503, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_header.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge 'Amazon' df & 'clean header' df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanish_final = final_header.merge(clean_amazon, on='amazonid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(cleanish_final, open(\"cleanish_amazon.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean 'Amazon' df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_cleaner(feature):\n",
    "    empty_list = []\n",
    "    for s in cleaner_amazon[feature]:\n",
    "        s = re.sub(\"[^0-9]\", \"\", s)\n",
    "        empty_list.append(s)\n",
    "    return empty_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## stars, reviews, ranks, publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_amazon = pickle.load(open(\"cleanish_amazon.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaner_amazon = clean_amazon.dropna(axis=0, how='any', subset= [\n",
    "    'stars', 'reviews', 'bs_rank', 'language'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "cleaner_amazon['reviews'] = feature_cleaner('reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "cleaner_amazon['bs_rank'] = feature_cleaner('bs_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "stars = []\n",
    "for s in cleaner_amazon['stars']:\n",
    "    s = s.replace(' out of 5 stars', '')\n",
    "    stars.append(s)\n",
    "cleaner_amazon['stars'] = stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "years = []\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    s = re.sub(\"[^0-9]\", \"\", s)[-4:]\n",
    "    years.append(s)\n",
    "cleaner_amazon['years'] = years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Publishers\n",
    "### Smaller publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    s = s.replace('Publisher: ', '')\n",
    "    publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cleaner_amazon['publisher'] = cleaner_amazon['publisher'].apply(lambda x: x.split('(')[0]).apply(lambda x: x.split(';')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    s = s.strip()\n",
    "    s = s.replace('.', '').replace(',', '').replace(' and ', ' & ')\n",
    "    publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    s = s.replace('Bantam Press', 'Bantam').replace('Bantam Spectra', 'Bantam')\n",
    "    publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    s = s.replace(\"G P Putnam's Sons\", 'G P Putnam').replace(\n",
    "        \"GP Putnam's Sons\", 'G P Putnam').replace(\n",
    "        'Putnam Adult', 'G P Putnam').replace(\n",
    "        'Putnam', 'G P Putnam').replace(\n",
    "        'G P G P Putnam', 'G P Putnam')\n",
    "     \n",
    "    publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    s = s.replace('Bloomsbury Children\\'s Books', 'Bloomsbury').replace(\n",
    "        'Bloomsbury Publishing', 'Bloomsbury').replace(\n",
    "        'Bloomsbury Publishing PLC', 'Bloomsbury').replace(\n",
    "        'Bloomsbury USA', 'Bloomsbury').replace('Bloomsbury PLC', 'Bloomsbury')\n",
    "    \n",
    "    publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    s = s.replace('Dutton Adult', 'Dutton').replace('Dutton Books', 'Dutton')\n",
    "    publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    s = s.replace('Delacorte Books for Young Readers', 'Delacorte Press')\n",
    "    publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    s = s.replace('Scholastic Inc', 'Scholastic').replace(\n",
    "        'Scholastic Paperbacks', 'Scholastic').replace('Scholastic Press', 'Scholastic')\n",
    "    publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    s = s.replace('Houghton Mifflin Company', 'Houghton Mifflin').replace(\n",
    "        'Houghton Mifflin Harcourt', 'Houghton Mifflin')\n",
    "    publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    s = s.replace('Signet Classics', 'Signet')\n",
    "    publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    s = s.replace('Viking Adult', 'Viking').replace(\n",
    "        'Viking Books for Young Readers', 'Viking')\n",
    "    publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big5 Publisher: Simon and Schuster's publishing divisions and imprints include Atria, Folger Shakespeare Library, Free Press, Gallery Books, Howard Books, Pocket Books, Scribner, Simon & Schuster, Threshold Editions and Touchstone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "big_five = ['SIMON & SCHUSTER LTD', 'Atria', 'Atria Books', 'Pocket', 'Pocket Books', \n",
    "            'Pocket Star', 'Scribner', 'Touchstone', \n",
    "            'Playboy Press : trade distribution by Simon & Schuster']\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    if s in big_five:\n",
    "        s = s.replace(s, 'Simon & Schuster')\n",
    "        publisher.append(s)\n",
    "    else:\n",
    "        publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big5 Publisher: As a result, Penguin Random House has nearly 250 imprints and publishing houses. Some of the most well-known Penguin Random House publishing groups are: Random House Publishing Group, Knopf Doubleday Publishing Group; Crown Publishing Group; Penguin Group U.S.; Dorling Kindersley; Mass Market Paperbacks, Penguin Group U.S.; Random House Children's Books; Penguin Young Readers Group, U.S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "big_five = ['Penguin Books Ltd', 'Penguin Classic', 'Penguin Classics', 'Penguin Press HC The', \n",
    "           'Penguin Putnam~childrens Hc', 'Random House Books for Young Readers', \n",
    "           'Random House Value Publishing', 'Alfred A Knopf', 'Knopf', 'Random House',\n",
    "            'Knopf Books for Young Readers', 'Doubleday','Crown','Penguin Bookss', 'Penguin Books']\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    if s in big_five:\n",
    "        s = s.replace(s, 'Penguin Random House')\n",
    "        publisher.append(s)\n",
    "    else:\n",
    "        publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big5 Publisher: Hachette's publishing divisions include Grand Central Publishing; Little, Brown and Company; Little, Brown and Company Books for Young Readers; Faith Words; Center Street; Orbit; Yen Press; Hachette Audio; and Hachette Digital. Read about Forever, Hachette's Romance line, and about Forever Yours, their digital first Romance line. Time Warner acquired Little, Brown in 1968 and HBG was created when Hachette Livre acquired Time Warner Book Group in 2006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "big_five = ['Little Brown & Co', 'Little Brown', 'Little Brown & Company', 'Little Brownmpany',\n",
    "            'Warner Books', 'Warner',\n",
    "            'Little Brown Book Group', 'Little Brown Books for Young Readers', \n",
    "            'Grand Central Publishing',]\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    if s in big_five:\n",
    "        s = s.replace(s, 'Hachette Books')\n",
    "        publisher.append(s)\n",
    "    else:\n",
    "        publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big5 Publisher: Some of HarperCollins publishers and imprints are: HaperCollins; William Morrow; Avon Books; Broadside Books; Harper Business; HarperCollinsChildrens; HarperTeen; Ecco Books; It Books; Newmarket Press; Harper One; Harper Voyager US; Harper Perennial; HarperAcademic and Harper Audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "big_five = ['HarperCollins', 'HarperCollins Design', 'HarperCollins Perennial', \n",
    "            'HarperCollinsCollins', 'HarperCollinsFestival', 'HarperCollinsTeen', 'HarperCollinsTorch', \n",
    "            'HarperCollinscollins', \"HarperCollinscollins Children's Books\", 'William Morrow & Co', \n",
    "            'William Morrow', 'Ecco', 'It Books']\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    if s in big_five:\n",
    "        s = s.replace(s, 'HarperCollins')\n",
    "        publisher.append(s)\n",
    "    else:\n",
    "        publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big5 Publisher: The Macmillan U.S. trade book publishers include Farrar, Straus and Giroux; Henry Holt and Company; Picador; St. Martin’s Press; Tor/Forge; Macmillan Audio; and Macmillan Children’s Publishing Group. Macmillan also publishes into the college and academic book marketplace. In the many of the Macmillan U.S. publishers headquartered in New York City's historic Flatiron Building.\n",
    "https://www.thebalance.com/the-big-five-trade-book-publishers-2800047\n",
    "Updated April 24, 2017 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "publisher = []\n",
    "big_five = [\"St Martin's Griffin\", \"St Martin's Paperbacks\", 'St Martins Pr', \"St Martin's Press\", \n",
    "            'Farrar Straus & Giroux', 'Henry Holt & Co', 'Picador', 'Tor Books','Forge',\n",
    "            'Forge Books']\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    if s in big_five:\n",
    "        s = s.replace(s, \"Macmillan\")\n",
    "        publisher.append(s)\n",
    "    else:\n",
    "        publisher.append(s)\n",
    "cleaner_amazon['publisher'] = publisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Publishing Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "big_publishing = []\n",
    "big_five = ['Penguin Random House', 'Hachette Books', 'Simon & Schuster', \n",
    "                  'HarperCollins', 'Macmillan']\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    if s in big_five:\n",
    "        big_publishing.append(1)\n",
    "    else:\n",
    "        big_publishing.append(0)\n",
    "cleaner_amazon['big_publishing'] = big_publishing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dummy Publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PRH_dummy = []\n",
    "big_five = ['Penguin Random House']\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    if s in big_five:\n",
    "        PRH_dummy.append(1)\n",
    "    else:\n",
    "        PRH_dummy.append(0)\n",
    "cleaner_amazon['PRH_dummy'] = PRH_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H_Books_dummy = []\n",
    "big_five = ['Hachette Books']\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    if s in big_five:\n",
    "        H_Books_dummy.append(1)\n",
    "    else:\n",
    "        H_Books_dummy.append(0)\n",
    "cleaner_amazon['H_Books_dummy'] = H_Books_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS_dummy = []\n",
    "big_five = ['Simon & Schuster']\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    if s in big_five:\n",
    "        SS_dummy.append(1)\n",
    "    else:\n",
    "        SS_dummy.append(0)\n",
    "cleaner_amazon['SS_dummy'] = SS_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HC_dummy = []\n",
    "big_five = ['HarperCollins']\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    if s in big_five:\n",
    "        HC_dummy.append(1)\n",
    "    else:\n",
    "        HC_dummy.append(0)\n",
    "cleaner_amazon['HC_dummy'] = HC_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mac_dummy = []\n",
    "big_five = ['Macmillan']\n",
    "for s in cleaner_amazon['publisher']:\n",
    "    if s in big_five:\n",
    "        Mac_dummy.append(1)\n",
    "    else:\n",
    "        Mac_dummy.append(0)\n",
    "cleaner_amazon['Mac_dummy'] = Mac_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(cleaner_amazon, open(\"cleaner_amazon.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
